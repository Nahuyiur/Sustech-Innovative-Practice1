@article{radford2021learning,
  author       = {Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
  title        = {Learning Transferable Visual Models From Natural Language Supervision},
  journal      = {arXiv preprint arXiv:2103.00020},
  year         = {2021},
  url          = {https://arxiv.org/abs/2103.00020},
  archivePrefix= {arXiv},
  eprint       = {2103.00020},
  primaryClass = {cs.CV}
}

@article{jia2021scaling,
  author       = {Chao Jia and Yinfei Yang and Ye Xia and Yi{-}Ting Chen and Zarana Parekh and Hieu Pham and Quoc V. Le and Yunhsuan Sung and Zhen Li and Tom Duerig},
  title        = {Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision},
  journal      = {arXiv preprint arXiv:2102.05918},
  year         = {2021},
  url          = {https://arxiv.org/abs/2102.05918},
  archivePrefix= {arXiv},
  eprint       = {2102.05918},
  primaryClass = {cs.CV},
  note         = {Presented at ICML 2021}
}


@article{xue2022clipvip,
  author       = {Hongwei Xue and Yuchong Sun and Bei Liu and Jianlong Fu and Ruihua Song and Houqiang Li and Jiebo Luo},
  title        = {CLIP-ViP: Adapting Pre-trained Image-Text Model to Video-Language Representation Alignment},
  journal      = {arXiv preprint arXiv:2209.06430},
  year         = {2022},
  url          = {https://arxiv.org/abs/2209.06430},
  archivePrefix= {arXiv},
  eprint       = {2209.06430},
  primaryClass = {cs.CV},
  note         = {Accepted by ICLR 2023}
}

@article{chen2023vast,
  author       = {Sihan Chen and Handong Li and Qunbo Wang and Zijia Zhao and Mingzhen Sun and Xinxin Zhu and Jing Liu},
  title        = {VAST: A Vision-Audio-Subtitle-Text Omni-Modality Foundation Model and Dataset},
  journal      = {arXiv preprint arXiv:2305.18500},
  year         = {2023},
  url          = {https://arxiv.org/abs/2305.18500},
  archivePrefix= {arXiv},
  eprint       = {2305.18500},
  primaryClass = {cs.CV},
  note         = {Accepted by NeurIPS 2023}
}


@article{bain2021frozen,
  author       = {Max Bain and Arsha Nagrani and G{\"u}l Varol and Andrew Zisserman},
  title        = {Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval},
  journal      = {arXiv preprint arXiv:2104.00650},
  year         = {2021},
  url          = {https://arxiv.org/abs/2104.00650},
  archivePrefix= {arXiv},
  eprint       = {2104.00650},
  primaryClass = {cs.CV},
  note         = {Accepted by ICCV 2021}
}


@article{arai2024covla,
  author       = {Hidehisa Arai and Keita Miwa and Kento Sasaki and Yu Yamaguchi and Kohei Watanabe and Shunsuke Aoki and Issei Yamamoto},
  title        = {{CoVLA}: Comprehensive Vision-Language-Action Dataset for Autonomous Driving},
  journal      = {arXiv preprint arXiv:2408.10845},
  year         = {2024},
  url          = {https://arxiv.org/abs/2408.10845},
  archivePrefix= {arXiv},
  eprint       = {2408.10845},
  primaryClass = {cs.CV},
  note         = {Accepted by WACV 2025}
}

@article{sima2023drivelm,
  author       = {Chonghao Sima and Katrin Renz and Kashyap Chitta and Li Chen and Hanxue Zhang and Chengen Xie and Jens Bei√üwenger and Ping Luo and Andreas Geiger and Hongyang Li},
  title        = {{DriveLM}: Driving with Graph Visual Question Answering},
  journal      = {arXiv preprint arXiv:2312.14150},
  year         = {2023},
  note         = {Accepted to ECCV 2024 as Oral paper},
  url          = {https://arxiv.org/abs/2312.14150},
  archivePrefix= {arXiv},
  eprint       = {2312.14150},
  primaryClass = {cs.CV}
}


@article{cheng2024videollama,
  author       = {Zesen Cheng and Sicong Leng and Hang Zhang and Yifei Xin and Xin Li and Guanzheng Chen and Yongxin Zhu and Wenqi Zhang and Ziyang Luo and Deli Zhao and Lidong Bing},
  title        = {{VideoLLaMA 2}: Advancing Spatial-Temporal Modeling and Audio Understanding in Video-LLMs},
  journal      = {arXiv preprint arXiv:2406.07476},
  year         = {2024},
  note         = {ZC, SL, HZ, YX, and XL contributed equally.},
  url          = {https://arxiv.org/abs/2406.07476},
  archivePrefix= {arXiv},
  eprint       = {2406.07476},
  primaryClass = {cs.CV}
}


@article{li2023videochat,
  author       = {KunChang Li and Yinan He and Yi Wang and Yizhuo Li and Wenhai Wang and Ping Luo and Yali Wang and Limin Wang and Yu Qiao},
  title        = {{VideoChat}: Chat-Centric Video Understanding},
  journal      = {arXiv preprint arXiv:2305.06355},
  year         = {2023},
  note         = {Technical report},
  url          = {https://arxiv.org/abs/2305.06355},
  archivePrefix= {arXiv},
  eprint       = {2305.06355},
  primaryClass = {cs.CV}
}


@inproceedings{lin2024videollava,
  author    = {Bin Lin and Yang Ye and Bin Zhu and Jiaxi Cui and Munan Ning and Peng Jin and Li Yuan},
  title     = {Video-{LLaVA}: Learning United Visual Representation by Alignment Before Projection},
  booktitle = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages     = {5971--5984},
  year      = {2024},
  address   = {Miami, Florida, USA},
  publisher = {Association for Computational Linguistics},
  doi       = {10.18653/v1/2024.emnlp-main.342},
  url       = {https://aclanthology.org/2024.emnlp-main.342/}
}